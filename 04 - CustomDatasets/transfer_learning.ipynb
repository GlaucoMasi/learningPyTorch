{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d8301a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "from torchvision import transforms, datasets\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fdfbfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9848fc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing to the 224x224 standard and using normalization \n",
    "\n",
    "simple_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_transform_trivial_augment = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a82003e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "venv_dir = Path(sys.prefix)\n",
    "project_root = venv_dir.parent\n",
    "image_path = project_root/\"data/food-101-pizzasteaksushi/images\"\n",
    "\n",
    "dataset = datasets.ImageFolder(\n",
    "    root=image_path,\n",
    "    transform=train_transform_trivial_augment,\n",
    ")\n",
    "\n",
    "train_size = int(0.8*len(dataset))\n",
    "train_dataset, test_dataset = random_split(dataset=dataset, lengths=[train_size, len(dataset)-train_size])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94a17377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module, optimizer: torch.optim.Optimizer):\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    for (X, y) in iter(dataloader):\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        y_pred = model(X)\n",
    "\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "    train_acc /= len(dataloader)\n",
    "    train_loss /= len(dataloader)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test_step(model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module):\n",
    "    model.eval()\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for (X, y) in iter(dataloader):\n",
    "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "            y_pred = model(X)\n",
    "\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "            test_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "    test_acc /= len(dataloader)\n",
    "    test_loss /= len(dataloader)\n",
    "    return test_loss, test_acc\n",
    "\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, test_dataloader: torch.utils.data.DataLoader, \n",
    "          loss_fn: torch.nn.Module, optimizer: torch.optim.Optimizer, scheduler=None,\n",
    "          epochs=5):\n",
    "    results = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": [],\n",
    "    }\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model, train_dataloader, loss_fn, optimizer)\n",
    "        test_loss, test_acc = test_step(model, test_dataloader, loss_fn)\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ece9240b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "ResNet                                   --\n",
      "├─Conv2d: 1-1                            9,408\n",
      "├─BatchNorm2d: 1-2                       128\n",
      "├─ReLU: 1-3                              --\n",
      "├─MaxPool2d: 1-4                         --\n",
      "├─Sequential: 1-5                        --\n",
      "│    └─BasicBlock: 2-1                   --\n",
      "│    │    └─Conv2d: 3-1                  36,864\n",
      "│    │    └─BatchNorm2d: 3-2             128\n",
      "│    │    └─ReLU: 3-3                    --\n",
      "│    │    └─Conv2d: 3-4                  36,864\n",
      "│    │    └─BatchNorm2d: 3-5             128\n",
      "│    └─BasicBlock: 2-2                   --\n",
      "│    │    └─Conv2d: 3-6                  36,864\n",
      "│    │    └─BatchNorm2d: 3-7             128\n",
      "│    │    └─ReLU: 3-8                    --\n",
      "│    │    └─Conv2d: 3-9                  36,864\n",
      "│    │    └─BatchNorm2d: 3-10            128\n",
      "├─Sequential: 1-6                        --\n",
      "│    └─BasicBlock: 2-3                   --\n",
      "│    │    └─Conv2d: 3-11                 73,728\n",
      "│    │    └─BatchNorm2d: 3-12            256\n",
      "│    │    └─ReLU: 3-13                   --\n",
      "│    │    └─Conv2d: 3-14                 147,456\n",
      "│    │    └─BatchNorm2d: 3-15            256\n",
      "│    │    └─Sequential: 3-16             8,448\n",
      "│    └─BasicBlock: 2-4                   --\n",
      "│    │    └─Conv2d: 3-17                 147,456\n",
      "│    │    └─BatchNorm2d: 3-18            256\n",
      "│    │    └─ReLU: 3-19                   --\n",
      "│    │    └─Conv2d: 3-20                 147,456\n",
      "│    │    └─BatchNorm2d: 3-21            256\n",
      "├─Sequential: 1-7                        --\n",
      "│    └─BasicBlock: 2-5                   --\n",
      "│    │    └─Conv2d: 3-22                 294,912\n",
      "│    │    └─BatchNorm2d: 3-23            512\n",
      "│    │    └─ReLU: 3-24                   --\n",
      "│    │    └─Conv2d: 3-25                 589,824\n",
      "│    │    └─BatchNorm2d: 3-26            512\n",
      "│    │    └─Sequential: 3-27             33,280\n",
      "│    └─BasicBlock: 2-6                   --\n",
      "│    │    └─Conv2d: 3-28                 589,824\n",
      "│    │    └─BatchNorm2d: 3-29            512\n",
      "│    │    └─ReLU: 3-30                   --\n",
      "│    │    └─Conv2d: 3-31                 589,824\n",
      "│    │    └─BatchNorm2d: 3-32            512\n",
      "├─Sequential: 1-8                        --\n",
      "│    └─BasicBlock: 2-7                   --\n",
      "│    │    └─Conv2d: 3-33                 1,179,648\n",
      "│    │    └─BatchNorm2d: 3-34            1,024\n",
      "│    │    └─ReLU: 3-35                   --\n",
      "│    │    └─Conv2d: 3-36                 2,359,296\n",
      "│    │    └─BatchNorm2d: 3-37            1,024\n",
      "│    │    └─Sequential: 3-38             132,096\n",
      "│    └─BasicBlock: 2-8                   --\n",
      "│    │    └─Conv2d: 3-39                 2,359,296\n",
      "│    │    └─BatchNorm2d: 3-40            1,024\n",
      "│    │    └─ReLU: 3-41                   --\n",
      "│    │    └─Conv2d: 3-42                 2,359,296\n",
      "│    │    └─BatchNorm2d: 3-43            1,024\n",
      "├─AdaptiveAvgPool2d: 1-9                 --\n",
      "├─Linear: 1-10                           1,539\n",
      "=================================================================\n",
      "Total params: 11,178,051\n",
      "Trainable params: 11,178,051\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231ed657e48a4b1a92d03c73f34a9b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.0576 | train_acc: 0.4529 | test_loss: 0.9670 | test_acc: 0.5367\n",
      "Epoch: 2 | train_loss: 0.8848 | train_acc: 0.6450 | test_loss: 0.8234 | test_acc: 0.6908\n",
      "Epoch: 3 | train_loss: 0.7674 | train_acc: 0.7462 | test_loss: 0.7264 | test_acc: 0.7555\n",
      "Epoch: 4 | train_loss: 0.6922 | train_acc: 0.7804 | test_loss: 0.6635 | test_acc: 0.7966\n",
      "Epoch: 5 | train_loss: 0.6376 | train_acc: 0.8042 | test_loss: 0.6064 | test_acc: 0.8070\n",
      "Epoch: 6 | train_loss: 0.5971 | train_acc: 0.8200 | test_loss: 0.5690 | test_acc: 0.8328\n",
      "Epoch: 7 | train_loss: 0.5541 | train_acc: 0.8333 | test_loss: 0.5639 | test_acc: 0.8147\n",
      "Epoch: 8 | train_loss: 0.5383 | train_acc: 0.8446 | test_loss: 0.5384 | test_acc: 0.8235\n",
      "Epoch: 9 | train_loss: 0.5167 | train_acc: 0.8363 | test_loss: 0.5187 | test_acc: 0.8224\n",
      "Epoch: 10 | train_loss: 0.5088 | train_acc: 0.8462 | test_loss: 0.4913 | test_acc: 0.8558\n",
      "Epoch: 11 | train_loss: 0.4871 | train_acc: 0.8433 | test_loss: 0.4723 | test_acc: 0.8657\n",
      "Epoch: 12 | train_loss: 0.4777 | train_acc: 0.8442 | test_loss: 0.4741 | test_acc: 0.8520\n",
      "Epoch: 13 | train_loss: 0.4686 | train_acc: 0.8496 | test_loss: 0.4386 | test_acc: 0.8679\n",
      "Epoch: 14 | train_loss: 0.4433 | train_acc: 0.8617 | test_loss: 0.4353 | test_acc: 0.8618\n",
      "Epoch: 15 | train_loss: 0.4376 | train_acc: 0.8621 | test_loss: 0.4333 | test_acc: 0.8596\n",
      "Epoch: 16 | train_loss: 0.4339 | train_acc: 0.8638 | test_loss: 0.4443 | test_acc: 0.8421\n",
      "Epoch: 17 | train_loss: 0.4281 | train_acc: 0.8512 | test_loss: 0.4257 | test_acc: 0.8569\n",
      "Epoch: 18 | train_loss: 0.4278 | train_acc: 0.8604 | test_loss: 0.4261 | test_acc: 0.8558\n",
      "Epoch: 19 | train_loss: 0.4153 | train_acc: 0.8625 | test_loss: 0.4073 | test_acc: 0.8662\n",
      "Epoch: 20 | train_loss: 0.4060 | train_acc: 0.8658 | test_loss: 0.4084 | test_acc: 0.8536\n",
      "Total training time: 544.518 seconds\n"
     ]
    }
   ],
   "source": [
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# resnet18 is pretrained on 1000 classes, we will modify is final fully connected layer for 3 classes\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 3)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "print(summary(model))\n",
    "\n",
    "# Freezing base layers parameters, to only train the final layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.001)\n",
    "\n",
    "start_time = timer()\n",
    "model_results = train(model, train_dataloader, test_dataloader, loss_fn, optimizer, epochs=NUM_EPOCHS)\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f607d643",
   "metadata": {},
   "source": [
    "Model achieves 85% accuracy, I will now do some fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba23a670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95db8cd23cab4b538c1d4fbe15a6f418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.4634 | train_acc: 0.8192 | test_loss: 0.4122 | test_acc: 0.8520\n",
      "Epoch: 2 | train_loss: 0.4248 | train_acc: 0.8425 | test_loss: 0.3813 | test_acc: 0.8640\n",
      "Epoch: 3 | train_loss: 0.3908 | train_acc: 0.8446 | test_loss: 0.3939 | test_acc: 0.8492\n",
      "Epoch: 4 | train_loss: 0.3686 | train_acc: 0.8583 | test_loss: 0.3618 | test_acc: 0.8536\n",
      "Epoch: 5 | train_loss: 0.3769 | train_acc: 0.8554 | test_loss: 0.4615 | test_acc: 0.8213\n",
      "Epoch: 6 | train_loss: 0.3587 | train_acc: 0.8625 | test_loss: 0.3749 | test_acc: 0.8487\n",
      "Epoch: 7 | train_loss: 0.3293 | train_acc: 0.8767 | test_loss: 0.3279 | test_acc: 0.8586\n",
      "Epoch: 8 | train_loss: 0.3237 | train_acc: 0.8796 | test_loss: 0.3443 | test_acc: 0.8602\n",
      "Epoch: 9 | train_loss: 0.3373 | train_acc: 0.8717 | test_loss: 0.3524 | test_acc: 0.8635\n",
      "Epoch: 10 | train_loss: 0.3171 | train_acc: 0.8838 | test_loss: 0.3156 | test_acc: 0.8695\n",
      "Epoch: 11 | train_loss: 0.3034 | train_acc: 0.8733 | test_loss: 0.3232 | test_acc: 0.8668\n",
      "Epoch: 12 | train_loss: 0.3092 | train_acc: 0.8779 | test_loss: 0.3430 | test_acc: 0.8613\n",
      "Epoch: 13 | train_loss: 0.3095 | train_acc: 0.8862 | test_loss: 0.3325 | test_acc: 0.8739\n",
      "Epoch: 14 | train_loss: 0.2891 | train_acc: 0.8904 | test_loss: 0.3014 | test_acc: 0.8904\n",
      "Epoch: 15 | train_loss: 0.2941 | train_acc: 0.8950 | test_loss: 0.3272 | test_acc: 0.8871\n",
      "Epoch: 16 | train_loss: 0.3029 | train_acc: 0.8758 | test_loss: 0.3242 | test_acc: 0.8684\n",
      "Epoch: 17 | train_loss: 0.2664 | train_acc: 0.9042 | test_loss: 0.3176 | test_acc: 0.8799\n",
      "Epoch: 18 | train_loss: 0.3016 | train_acc: 0.8879 | test_loss: 0.3366 | test_acc: 0.8712\n",
      "Epoch: 19 | train_loss: 0.2803 | train_acc: 0.8992 | test_loss: 0.2963 | test_acc: 0.8997\n",
      "Epoch: 20 | train_loss: 0.3077 | train_acc: 0.8862 | test_loss: 0.3424 | test_acc: 0.8701\n",
      "Total training time: 701.340 seconds\n"
     ]
    }
   ],
   "source": [
    "# Unfreezing the last ResNet block, lowering learning rate and giving the optimizer only the unfrozen parameters with separate learning rates\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if \"layer4\" in name or \"fc\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.SGD([\n",
    "    {'params': model.layer4.parameters(), 'lr': 0.0001},\n",
    "    {'params': model.fc.parameters(), 'lr': 0.001}\n",
    "], momentum=0.9)\n",
    "\n",
    "\n",
    "# Improving data augmentation\n",
    "better_train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "venv_dir = Path(sys.prefix)\n",
    "project_root = venv_dir.parent\n",
    "image_path = project_root/\"data/food-101-pizzasteaksushi/images\"\n",
    "\n",
    "dataset = datasets.ImageFolder(\n",
    "    root=image_path,\n",
    "    transform=better_train_transform,\n",
    ")\n",
    "\n",
    "train_size = int(0.8*len(dataset))\n",
    "train_dataset, test_dataset = random_split(dataset=dataset, lengths=[train_size, len(dataset)-train_size])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False)\n",
    "\n",
    "\n",
    "# Adding learning rate scheduling and using it in training loop\n",
    "# Gives smoother scheduling compared to StepLR\n",
    "scheduler = CosineAnnealingLR(optimizer=optimizer, T_max=NUM_EPOCHS)\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "start_time = timer()\n",
    "model_results = train(model, train_dataloader, test_dataloader, loss_fn, optimizer, scheduler=scheduler, epochs=NUM_EPOCHS)\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ce2f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "venv_dir = Path(sys.prefix)\n",
    "project_root = venv_dir.parent\n",
    "models_path = project_root/\"trained_models\"\n",
    "\n",
    "torch.save(model.state_dict(), models_path/\"resnet18_pizzasushisteak.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
